{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DarthMaulCSIE/AI-Demo/blob/master/%E3%80%90Demo06b%E3%80%91RAG02_%E6%89%93%E9%80%A0_RAG_%E7%B3%BB%E7%B5%B1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0. è®€å…¥ä½ æ‰“é€ å¥½çš„ vector dataset"
      ],
      "metadata": {
        "id": "b_9at2wXPVKN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install gdown"
      ],
      "metadata": {
        "id": "Usv4C3IOPeQc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GDRIVE_PUBLIC_URL = \"https://drive.google.com/uc?export=download&id=1MwJ-eCnKubk4Z5p33zwg6ZFyt6EY71v9\""
      ],
      "metadata": {
        "id": "KjlSvsjjPlff"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --fuzzy -O faiss_db.zip \"{GDRIVE_PUBLIC_URL}\""
      ],
      "metadata": {
        "id": "cIN_fDuGQDPL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07e69d8c-d422-4c5c-e86c-f286f91d87ba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1MwJ-eCnKubk4Z5p33zwg6ZFyt6EY71v9\n",
            "To: /content/faiss_db.zip\n",
            "\r  0% 0.00/27.3k [00:00<?, ?B/s]\r100% 27.3k/27.3k [00:00<00:00, 40.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip faiss_db.zip"
      ],
      "metadata": {
        "id": "rhPQD5g0_l5Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4ac11ec-e8b9-4119-d701-cc27bda8dd63"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  faiss_db.zip\n",
            "replace faiss_db/index.faiss? [y]es, [n]o, [A]ll, [N]one, [r]ename: Ay\n",
            "  inflating: faiss_db/index.faiss    \n",
            "  inflating: faiss_db/index.pkl      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. å®‰è£ä¸¦å¼•å…¥å¿…è¦å¥—ä»¶"
      ],
      "metadata": {
        "id": "Cc-facvpBkIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install -qU langchain langchain_community langchain_openai langchain_text_splitters\n",
        "\n",
        "!pip install -qU pypdf python-docx sentence-transformers transformers faiss-cpu huggingface_hub gradio wget gdown\n",
        "\n",
        "!pip install -qU openai\n",
        "!pip -q install \"aisuite[all]\""
      ],
      "metadata": {
        "id": "9JThdfm-CVZZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9735627-0e86-4b7d-a914-b4012c24909d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m323.9/323.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m948.6/948.6 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_openai import ChatOpenAI"
      ],
      "metadata": {
        "id": "L1zqb7F8BMP3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import gradio as gr"
      ],
      "metadata": {
        "id": "PTx3Q75QBp_J"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. è‡ªè¨‚ E5 embedding é¡žåˆ¥"
      ],
      "metadata": {
        "id": "z13eoo6uCnTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "SnWbtp6GvXLa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hf_token = userdata.get('HuggingFace')"
      ],
      "metadata": {
        "id": "b1-hZ354vxfo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(token=hf_token)"
      ],
      "metadata": {
        "id": "wvNFzV9jv2Ib"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingGemmaEmbeddings(HuggingFaceEmbeddings):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(\n",
        "            model_name=\"google/embeddinggemma-300m\",\n",
        "            encode_kwargs={\"normalize_embeddings\": True},\n",
        "            **kwargs\n",
        "        )\n",
        "\n",
        "    def embed_documents(self, texts):\n",
        "        # ä½ ä¹Ÿå¯ä»¥æŠŠ \"none\" æ”¹æˆçœŸå¯¦æ¨™é¡Œï¼ˆæª”å/ç« ç¯€åï¼‰ï¼Œæ•ˆæžœæœƒæ›´ç©©\n",
        "        texts = [f\"title: none | text: {t}\" for t in texts]\n",
        "        return super().embed_documents(texts)\n",
        "\n",
        "    def embed_query(self, text):\n",
        "        # å®˜æ–¹æª¢ç´¢å»ºè­°å‰ç¶´\n",
        "        return super().embed_query(f\"task: search result | query: {text}\")"
      ],
      "metadata": {
        "id": "HkmvGTaECfTY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. è¼‰å…¥ `faiss_db`"
      ],
      "metadata": {
        "id": "NkXNMQs5RbNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model = EmbeddingGemmaEmbeddings()\n",
        "vectorstore = FAISS.load_local(\n",
        "    \"faiss_db\",\n",
        "    embeddings=embedding_model,\n",
        "    allow_dangerous_deserialization=True\n",
        ")"
      ],
      "metadata": {
        "id": "LkELACdWCtpo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77e009c9-859a-4daa-cff4-f1463794317f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})"
      ],
      "metadata": {
        "id": "-tlYrXZWw2tL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. è¨­å®šå¥½æˆ‘å€‘è¦çš„ LLM"
      ],
      "metadata": {
        "id": "GrHSAsjcRkXF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "å¦‚ä¹‹å‰, æˆ‘å€‘æœƒç”¨ OpenAI APIã€‚é€™è£¡ä½¿ç”¨ Groq æœå‹™, å¯æ”¹æˆä½ è¦çš„æœå‹™ã€‚"
      ],
      "metadata": {
        "id": "WWgbNGakRwrp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import aisuite as ai"
      ],
      "metadata": {
        "id": "uIy_haAeQiB0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = userdata.get('OpenAI')"
      ],
      "metadata": {
        "id": "Xefdy-lkRtAL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['OPENAI_API_KEY']=api_key"
      ],
      "metadata": {
        "id": "K7UiOKuTDD5F"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "é€™è£¡çš„æ¨¡åž‹å’Œ `base_url` æ˜¯ç”¨ Groq, å¦‚æžœç”¨å…¶ä»–æœå‹™è«‹è‡ªè¡Œä¿®æ”¹ã€‚"
      ],
      "metadata": {
        "id": "654I7y52R8yO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"openai:gpt-4o\"\n",
        "#base_url=\"https://api.groq.com/openai/v1\""
      ],
      "metadata": {
        "id": "sqWfH90JFFWV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = ai.Client()"
      ],
      "metadata": {
        "id": "JnqlH0W9P2-Q"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. `prompt` è¨­è¨ˆ"
      ],
      "metadata": {
        "id": "K0egxeawSR41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"\"\"ä½ ç¾åœ¨æ˜¯ã€Šå“ˆåˆ©æ³¢ç‰¹ã€‹ä¸­çš„ã€Œéœ²å¨œÂ·ç¾…å¤å¾·ã€(Luna Lovegood)ã€‚ä½ èªªè©±é¢¨æ ¼ç©ºéˆã€å¤¢å¹»ï¼Œç›¸ä¿¡ä¸–ç•Œä¸Šå……æ»¿å¥‡ç‰¹çš„ç”Ÿç‰©ã€‚\"\"\"\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "æ ¹æ“šä¸‹åˆ—çš„ã€Šå“ˆåˆ©æ³¢ç‰¹ã€‹ä¸–ç•Œè§€è³‡æ–™ï¼š\n",
        "{retrieved_chunks}\n",
        "\n",
        "ç”¨ã€Œéœ²å¨œÂ·ç¾…å¤å¾·ã€çš„é¢¨æ ¼å›žç­”ä½¿ç”¨è€…çš„å•é¡Œï¼š{question}\n",
        "\n",
        "ä½ çš„å›žç­”è¦å‰‡ï¼š\n",
        "1.  é¢¨æ ¼ï¼šèªªè©±è¦è¼•é£„é£„ã€æœ‰é»žå¤¢å¹»ã€‚\n",
        "2.  çŸ¥è­˜ï¼šå„ªå…ˆä½¿ç”¨ä¸Šæ–¹æä¾›çš„è³‡æ–™å›žç­”ã€‚\n",
        "3.  å£é ­ç¦ªï¼šé©æ™‚ä½¿ç”¨ã€Œæˆ‘çŒœ...ã€ã€ã€Œæˆ‘æƒ³...ã€ã€ã€Œæˆ‘çˆ¸çˆ¸åœ¨ã€Šè¬¬è«–å®¶ã€‹ä¸ŠèªªéŽ...ã€ã€‚\n",
        "4.  é—œéµè©žï¼šå¯ä»¥æåˆ°ã€Œæ°´ç…™èŸ² (Nargles)ã€æˆ–ã€Œé¨·æ“¾èŸ² (Wrackspurts)ã€ã€‚\n",
        "5.  æœªçŸ¥ç­”æ¡ˆï¼šå¦‚æžœè³‡æ–™ä¸­æ²’æœ‰æåˆ°ï¼Œä¸è¦ç·¨é€ ã€‚èªªï¼šã€Œå“¦... é€™å€‹å•é¡Œå¾ˆæœ‰è¶£ã€‚å®ƒå¯èƒ½è¢«ã€Žé¨·æ“¾èŸ²ã€(Wrackspurts) å¼„æ¨¡ç³Šäº†...ã€æˆ–é¡žä¼¼çš„è©±ã€‚\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ZaUnqDpfFop-"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. ä½¿ç”¨ RAG ä¾†å›žæ‡‰\n",
        "\n",
        "æœå°‹èˆ‡ä½¿ç”¨è€…å•é¡Œç›¸é—œçš„è³‡è¨Šï¼Œæ ¹æ“šæˆ‘å€‘çš„ prompt æ¨£ç‰ˆåŽ»è®“ LLM å›žæ‡‰ã€‚"
      ],
      "metadata": {
        "id": "qw8azlVESghL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = []\n",
        "\n",
        "def chat_with_rag(user_input):\n",
        "    global chat_history\n",
        "    # å–å›žç›¸é—œè³‡æ–™\n",
        "    docs = retriever.invoke(user_input)\n",
        "    retrieved_chunks = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
        "\n",
        "    # å°‡è‡ªå®š prompt å¥—å…¥æ ¼å¼\n",
        "    final_prompt = prompt_template.format(retrieved_chunks=retrieved_chunks, question=user_input)\n",
        "\n",
        "    # ç”¨ AI Suite å‘¼å«èªžè¨€æ¨¡åž‹\n",
        "    response = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": final_prompt},\n",
        "    ]\n",
        "    )\n",
        "    answer = response.choices[0].message.content\n",
        "\n",
        "    chat_history.append((user_input, answer))\n",
        "    return answer"
      ],
      "metadata": {
        "id": "pWfDUb3mD-6X"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. ç”¨ Gradio æ‰“é€  Web App"
      ],
      "metadata": {
        "id": "5m7E7XmgTJUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# ðŸŽ“ å“ˆåˆ©æ³¢ç‰¹å¥‡å¹»ä¸–ç•Œ\")\n",
        "    chatbot = gr.Chatbot()\n",
        "    msg = gr.Textbox(placeholder=\"è«‹è¼¸å…¥ä½ çš„å•é¡Œ...\")\n",
        "\n",
        "    def respond(message, chat_history_local):\n",
        "        response = chat_with_rag(message)\n",
        "        chat_history_local.append((message, response))\n",
        "        return \"\", chat_history_local\n",
        "\n",
        "    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
        "\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "id": "YI5swv4AFa_U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        },
        "outputId": "f2bc2d5b-de8c-4ced-caeb-de9556770ad7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2625768015.py:3: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://36bf63e4454aa68e6f.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://36bf63e4454aa68e6f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://36bf63e4454aa68e6f.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d7uMRFduRywj"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}